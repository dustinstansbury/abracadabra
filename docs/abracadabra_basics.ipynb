{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Input-data\" data-toc-modified-id=\"Input-data-1\">Input data</a></span></li><li><span><a href=\"#Key-Components-of-an-AB-Test\" data-toc-modified-id=\"Key-Components-of-an-AB-Test-2\">Key Components of an AB Test</a></span><ul class=\"toc-item\"><li><span><a href=\"#Running-an-AB-test-in-✨abracadabra✨-is-as-easy-as-✨1,-2,-3✨:\" data-toc-modified-id=\"Running-an-AB-test-in-✨abracadabra✨-is-as-easy-as-✨1,-2,-3✨:-2.1\">Running an AB test in ✨abracadabra✨ is as easy as ✨1, 2, 3✨:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hypotheses\" data-toc-modified-id=\"Hypotheses-2.1.1\">Hypotheses</a></span></li><li><span><a href=\"#Inference-Methods\" data-toc-modified-id=\"Inference-Methods-2.1.2\">Inference Methods</a></span></li><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-2.1.3\">Example</a></span></li></ul></li></ul></li><li><span><a href=\"#Interpreting-results\" data-toc-modified-id=\"Interpreting-results-3\">Interpreting results</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Top-Plot:-Sample-Distributions\" data-toc-modified-id=\"Top-Plot:-Sample-Distributions-3.0.1\">Top Plot: Sample Distributions</a></span></li><li><span><a href=\"#Middle-Plot:-Central-Tendencies\" data-toc-modified-id=\"Middle-Plot:-Central-Tendencies-3.0.2\">Middle Plot: Central Tendencies</a></span></li><li><span><a href=\"#Bottom-Plot:-Deltas\" data-toc-modified-id=\"Bottom-Plot:-Deltas-3.0.3\">Bottom Plot: Deltas</a></span></li></ul></li></ul></li><li><span><a href=\"#Bayesian-Hypothesis-Tests\" data-toc-modified-id=\"Bayesian-Hypothesis-Tests-4\">Bayesian Hypothesis Tests</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bayesian-Model-Specification\" data-toc-modified-id=\"Bayesian-Model-Specification-4.1\">Bayesian Model Specification</a></span></li></ul></li><li><span><a href=\"#Including-Segmentations\" data-toc-modified-id=\"Including-Segmentations-5\">Including Segmentations</a></span></li><li><span><a href=\"#Running-multiple-tests,-and-multiple-comparison-control\" data-toc-modified-id=\"Running-multiple-tests,-and-multiple-comparison-control-6\">Running multiple tests, and multiple comparison control</a></span></li><li><span><a href=\"#Custom-Metrics\" data-toc-modified-id=\"Custom-Metrics-7\">Custom Metrics</a></span></li><li><span><a href=\"#Working-with-other-types-of-variables\" data-toc-modified-id=\"Working-with-other-types-of-variables-8\">Working with other types of variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Continuous-Variables\" data-toc-modified-id=\"Continuous-Variables-8.1\">Continuous Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bayesian-models-for-continuous-variables\" data-toc-modified-id=\"Bayesian-models-for-continuous-variables-8.1.1\">Bayesian models for continuous variables</a></span></li></ul></li><li><span><a href=\"#Counts-/-Rates-variables\" data-toc-modified-id=\"Counts-/-Rates-variables-8.2\">Counts / Rates variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bayesian-models-for-count-variables\" data-toc-modified-id=\"Bayesian-models-for-count-variables-8.2.1\">Bayesian models for count variables</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨abracadabra✨ Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data\n",
    "✨ABracadabra✨ takes as input a [pandas](https://pandas.pydata.org/) `DataFrame` containing experiment observations data. Each record represents an observation/trial recorded in the experiment and has the following columns:\n",
    "\n",
    "- **One or more `treatment` columns**: each treatment column contains two or more distinct, discrete values that are used to identify the different groups in the experiment\n",
    "- **One or more `metric` columns**: these are the values associated with each observation that are used to compare groups in the experiment.\n",
    "- **Zero or more `attributes` columns**: these are associated with additional properties assigned to the observations. These attributes can be used for any additional segmentations across groups.\n",
    "\n",
    "To demonstrate, let's generate some artificial experiment observations data. The `metric` column in our dataset will be a series of binary outcomes (i.e. `True`/`False`, here stored as `float` values). This binary `metric` is analogous to *conversion* or *success* in AB testing. These outcomes are simulated from three different Bernoulli distributions, each associated with the `treatement`s named `\"A\"`, `\"B\"`, and `\"C\"`. and each of which has an increasing average probability of *conversion*, respectively. The simulated data also contains four `attribute` columns, named `attr_*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'abra.inference'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5ed4cf25a0d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgenerate_fake_observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# generate some fake binary trial data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m binary_data = generate_fake_observations(\n\u001b[0;32m      5\u001b[0m     \u001b[0mdistribution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bernoulli'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# binary data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.pyenv/versions/3.7.0/lib/python3.7/site-packages/abra/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypothesis_test\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHypothesisTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHypothesisTestSuite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCustomMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultipleComparisonCorrection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.pyenv/versions/3.7.0/lib/python3.7/site-packages/abra/experiment.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInitRepr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDEFAULT_ALPHA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypothesis_test\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHypothesisTestSuiteResults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.pyenv/versions/3.7.0/lib/python3.7/site-packages/abra/hypothesis_test.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mensure_dataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDEFAULT_ALPHA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInferenceProcedure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_inference_procedure\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCORRECTIONS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'abra.inference'"
     ]
    }
   ],
   "source": [
    "from abra.utils import generate_fake_observations\n",
    "\n",
    "# generate some fake binary trial data\n",
    "binary_data = generate_fake_observations(\n",
    "    distribution='bernoulli',  # binary data\n",
    "    n_treatments=3,\n",
    "    n_attributes=4,\n",
    "    n_observations=1000\n",
    ")\n",
    "binary_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting data have a single `treatment` column, called (creatively) `'treatment'`, a single `metric` column, called `'metric'`, and four `attribute` columns, `atr_0`, `attr_1`, `attr_2`, and `attr_3`. The `treatment` column has 3 distinct treatments: `\"A\"`, `\"B\"`, and `\"C\"`, and the metric takes on boolean/binary values drawn from a [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Components of an AB Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three key components of running an AB test in ✨abracadabra✨ are:\n",
    "\n",
    "- **The `Experiment`**, which holds the raw observations data recorded from, and any metadata associated with an AB experiment.\n",
    "- **The `HypothesisTest`**, which defines the statistical inference procedure applied to the experiment data.\n",
    "- **The `HypothesisTestResults`**, which is the statistical artifact that results from running a `HypothesisTest` against an `Experiment`'s observations. The `HypothesisTestResults` are used to summarize, visulize, and interpret the inference results and make decisions based on these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running an AB test in ✨abracadabra✨ is as easy as ✨1, 2, 3✨:\n",
    "1. Initialize your `Experiment` with observations and any metadata\n",
    "2. Define your `HypothesisTest`. This requires defining the `hypothesis` and `inference_method`. The relevant inference method used will depend on the support of your observations. A list of supported hypotheses and inference methods for different types of observation variables are shown below:\n",
    "\n",
    "#### Hypotheses\n",
    "| Hypothesis | Hypothesis Type | `hypothesis` parameter  |\n",
    "|---|---|---|\n",
    "| \"The treatment is larger than the control\" | one-tailed | `\"larger\"` |\n",
    "| \"The treatment is smaller than the control\" | one-tailed | `\"smaller\"` |\n",
    "| \"The treatment is not equal to the control\" | two-tailed | `\"unequal\"` |\n",
    "\n",
    "\n",
    "#### Inference Methods\n",
    "\n",
    "| Variable Type | Model Class| `inference_method` parameter  |\n",
    "|---|---|---|\n",
    "| Continuous | Frequentist| `'means_delta'` (t-test) |\n",
    "|  | Bayesian| `'gaussian'`, `'exp_student_t'`|\n",
    "| Binary / Proportions | Frequentist| `'proportions_delta'` (z-test) |\n",
    "|  | Bayesian| `'beta'`, `'beta_binomial'`, `'bernoulli'`  |\n",
    "| Counts  |Frequentist| `'rates_ratio'`  |\n",
    "|  |Bayesian| `'gamma_poisson'`  |\n",
    "\n",
    "3. Run the test against your experiment and interpret the resulting `HypothesisTestResults`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Below we demonstrate a standard AB test workflow in ✨abracadabra✨. Namely we:\n",
    "1. Initialize an `Experiment` instance `exper` with our artifical binary observations generated above.\n",
    "2. We then initialize a `HypothesisTest` instance `ab_test` that tests if `treatment` `\"B\"` is `\"larger\"` than treatment `\"A\"` based on the metric values in the `\"metric\"` column of the dataframe. The hypothesis test uses a Frequentist method `'proportions_delta'` that is dedicated to detecting differences between binary samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abra import Experiment, HypothesisTest\n",
    "\n",
    "# Initialize the Experiment\n",
    "exper = Experiment(data=binary_data, name=\"Demo Experiment\")\n",
    "\n",
    "# Initialize the A/B test\n",
    "ab_test = HypothesisTest(\n",
    "    metric=\"metric\",\n",
    "    treatment=\"treatment\",\n",
    "    control=\"A\", variation=\"B\",\n",
    "    hypothesis=\"unequal\",\n",
    "    inference_method=\"proportions_delta\"\n",
    ")\n",
    "\n",
    "# Run the test with an alpha of 0.5; get back a HypothesisTestResults object\n",
    "ab_test_results = exper.run_test(ab_test, alpha=.05)\n",
    "\n",
    "# Check the test results decision\n",
    "assert ab_test_results.accept_hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting results\n",
    "Each `HypothesisTestResults` has its own `display()` and `visualize()` methods that can be used to interpret the results of the test. The `display()` method prints out the results to the console, while `visualize` plots a visual summary of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print the test results to the console\n",
    "ab_test_results.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Providing an `outfile` argument to the `visualize` method will save the results figure to an image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "# Visualize the test results\n",
    "outfile = '/tmp/abracadabra_demo_test_results.png'\n",
    "ab_test_results.visualize(outfile=outfile)\n",
    "\n",
    "# Show that results figure exists\n",
    "!ls -lah {outfile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting frequentist test results (displayed and visualized above) indicate that hypothesis `\"B != A\"` should be accepted. A breakdown of the results plot is as follows:\n",
    "\n",
    "#### Top Plot: Sample Distributions\n",
    "The top plot compares the _parameterized representation of the sample distributions_ with parameters being derived from the experiment observations.\n",
    "\n",
    "The large degree of separation between the two distributions indicates that the `\"B\"` group is qualitatively larger than `\"A\"`\n",
    "\n",
    "#### Middle Plot: Central Tendencies\n",
    "The middle plot compares the _central tendiency estimates_ of the two sample groups--in this case the, average probability of success on a given trial--as well as adds _Standard Errors_ calculate for the central tendency estimates.\n",
    "\n",
    "We can see that there is no overlap of the standard errors, further indicating that we can be confident that the two groups are likely different, and that `\"B\"` is larger than `\"A\"`.\n",
    "\n",
    "#### Bottom Plot: Deltas\n",
    "The bottom plot gives the estimate of the _difference in central tendencies_, in this case `ProportionsDelta`, as well as 95% Confidence Intervals on this difference estimate (This is a two-tailed test, checking that `\"B\"` is not equal to `\"A\"`, so the upper bound on ProportionsDelta is `inf`).\n",
    "\n",
    "We can see that the confidence interval on the difference between the two groups does not intersect with the `ProportionsDelta=0` line, indicating a statistically significant difference between the two samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Hypothesis Tests\n",
    "In addition to common Frequentist test, running Bayesian analogs is simple. Simply intitialize the `HypothesisTest` with a Bayesian `method` parameter. For example, the Bayesian analogs to the `'proportions_delta'` method are the `'binomial'`, `'beta_binomial'`, or `'bernoulli'` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binomial_ab_test = ab_test.copy(inference_method='binomial')\n",
    "\n",
    "# run the test\n",
    "binomial_ab_test_results = exper.run_test(binomial_ab_test)\n",
    "assert binomial_ab_test_results.prob_greater > .95\n",
    "binomial_ab_test_results.display()\n",
    "binomial_ab_test_results.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian `HypothesisTestResults` have their own analogous `display` and `visualize` methods that can be used to interpret the results of the analysis. Notice the results of the `ab_test_results` and `binomial_ab_test_results` each support a difference in proportions of approximately 0.14.\n",
    "\n",
    "Note how the mean parameter and 95% HDI sampled from the Bayesian model are very similar to the mean and 95% confidence interval used in the Frequentist test `ab_test_results`. Similarly, the deltas in proportion parameter $p$ sampled from the model provide aligned with the `ProportionsDelta` estiamted for the Frequentist test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Model Specification\n",
    "Bayesian models allow the experimenter to incorporate prior beliefs. This can be helpful when you have little data, or can provide sound domain knowledge of baselines. Specifying custom priors is also straight-forward using `abracadaba`, simply pass in a `model_params` argument during `HypothesisTest` initialization. Below we demonstrate by running another Bayesian hypothesis test, this time with a hierarchical [Beta-Binomial model](https://en.wikipedia.org/wiki/Beta-binomial_distribution#:~:text=In%20probability%20theory%20and%20statistics,is%20either%20unknown%20or%20random.). This model allows the user to specify a prior over the base probability $p$ by setting two hyperparameters for the Beta Distribution $\\alpha$ and $\\beta$ such that the mean prior has a value of \n",
    "\n",
    "$$ p = \\frac{\\alpha}{\\alpha + \\beta}$$\n",
    "\n",
    "where the larger $\\alpha$ and $\\beta$. Let's put a super-strong prior on $p$ and see how it affects the inference results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Bayesian test with custom priors\n",
    "\n",
    "# strong prior that p = alpha / (alpha + beta) = 0.33\n",
    "beta_prior_params = dict(alpha=500., beta=1000.)\n",
    "\n",
    "bb_ab_test = HypothesisTest(\n",
    "    metric='metric',\n",
    "    control='A', variation='C',\n",
    "    inference_method='beta_binomial',\n",
    "    model_params=beta_prior_params\n",
    ")\n",
    "\n",
    "# run the test\n",
    "bb_ab_test_results = exper.run_test(bb_ab_test)\n",
    "assert bb_ab_test_results.prob_greater > .95\n",
    "bb_ab_test_results.display()\n",
    "bb_ab_test_results.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the strong prior of $p=0.33$ influences the proportion parameters to values around 0.33. This causes our delta samples from the model be much smaller because two distributions that are forced to be near a prior value (here 0.33) will be located close to one another. Even with this strong prior, the model identifies that the two distributions are, in fact different, and that `P(C > A)` near 1.\n",
    "\n",
    "Note that if there were more data in the experiment, these parameter estimates would gradually move toward the data distribution, rather than the super-confident prior distribution, providing results that are similar to the results provided by the  `binomial`  (which can be thought of as a special case of the Beta-Binomial with a weak, agnostic prior) and `proportions_delta` inference methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including Segmentations\n",
    "✨abracdabra✨ supports the ability to segment experiment observations based on one or more attributes in your dataset using the `segmentation` argument to `HyptothesisTest`. The segmentation can be a string or list of string expressions, each of which follow the [pandas query API](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.query.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an A/B test with additional segmentation on the 'attr_1' attribute\n",
    "ab_test_segmented = HypothesisTest(\n",
    "    metric='metric',\n",
    "    control='A', variation='B',\n",
    "    inference_method='proportions_delta',\n",
    "    hypothesis='larger',\n",
    "    segmentation=\"attr_1 == 'A1a'\"\n",
    ")\n",
    "\n",
    "# Run the segmented test\n",
    "ab_test_segmented_results = exper.run_test(ab_test_segmented)\n",
    "assert not ab_test_segmented_results.accept_hypothesis  # B is larger\n",
    "\n",
    "# Display results (notice reduced sample sizes)\n",
    "ab_test_segmented_results.display()\n",
    "ab_test_segmented_results.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that if we dig into a particular segment, namely the segement defined by `\"attr_1 == 'A1a'\"`, we can no longer accept the hypothesis that `\"B is larger\"`. This is indicated by a `ProportionsDelta` that overlaps substantially with the line indicating `0` difference between the two samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running multiple tests, and multiple comparison control\n",
    "When running multiple tests on the same metric, you'll need to control for [multiple comparisons](https://en.wikipedia.org/wiki/Multiple_comparisons_problem). This is handled by running a `HypothesisTestSuite`, which takes in a list of hypothesis tests.\n",
    "\n",
    "Below we run 3 independent tests comparing A to A, B to A and C to A, and set the correction `method` to `'bonferonni'`, which simply updates the effective $\\alpha_{corrected} = \\frac{\\alpha}{N_{tests}}$. Our original value for `alpha=0.05`, thus the corrected value would be $\\frac{0.05}{3} = 0.0167$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abra.hypothesis_test import HypothesisTestSuite\n",
    "from copy import deepcopy\n",
    "\n",
    "# Use the `HypothesisTest.copy` method for duplicating test\n",
    "# configurations, while overwriting specific parameters, in\n",
    "# this case `variation` parameter\n",
    "aa_test = ab_test.copy(variation='A')\n",
    "ac_test = ab_test.copy(variation='C')\n",
    "\n",
    "# Initialize the `HypothesisTestSuite`\n",
    "test_suite = HypothesisTestSuite(\n",
    "    tests=[aa_test, ab_test, ac_test],\n",
    "    correction_method='bonferroni'\n",
    ")\n",
    "\n",
    "# Run tests\n",
    "test_suite_results = exper.run_test_suite(test_suite)\n",
    "\n",
    "print(test_suite_results)\n",
    "\n",
    "# Print results\n",
    "test_suite_results.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the alpha has been `corrected` with `MC Correction='bonferroni'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test_suite_results.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `HypothesisTestSuite` supports the following multiple comparison strategies:\n",
    "- [Sidak](http://en.wikipedia.org/wiki/%C5%A0id%C3%A1k_correction) (default)\n",
    "- [Bonferonni](http://en.wikipedia.org/wiki/Bonferroni_correction)\n",
    "- [Benjamini-Hochberg false-discovery rate](http://pdfs.semanticscholar.org/af6e/9cd1652b40e219b45402313ec6f4b5b3d96b.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Metrics\n",
    "✨abracadabra✨ also supports the use of custom metrics, which can transform and combine information from one or more columns. Below we create a `CustomMetric` always makes the `variation` greater than the `control` by adding a constant offset (plus noise) to the value of the the `control`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abra import CustomMetric\n",
    "import numpy as np\n",
    "\n",
    "def custom_metric(row):\n",
    "    \"\"\"\n",
    "    Define a custom 'metric' where the control is always better.\n",
    "    \"\"\"\n",
    "    return 4 + np.random.rand() if row['treatment'] == 'A' else np.random.rand()\n",
    "\n",
    "custom_test = HypothesisTest(\n",
    "    metric=CustomMetric(custom_metric),\n",
    "    control='A',\n",
    "    variation='B',\n",
    "    inference_method='means_delta',  # Note we use a t-test here\n",
    "    hypothesis='unequal'\n",
    ")\n",
    "\n",
    "custom_test = exper.run_test(custom_test)\n",
    "custom_test.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, as expected, we have highly significant results, accepting the hypothesis that `'B != A'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with other types of variables\n",
    "The examples above demonstrate running AB tests for variables that take on binary values--i.e. variables that take on values that exist in the interval $[0, 1]$. This is a pretty common scenario, as a lot of AB tests measure metrics like conversions at various stages in a UX funnel. However, ✨abracadabra✨ also supports inference methods for other types of variables, like continuous variables (e.g. time spent on a page) and counts/rate variables (e.g. number of clicks on a button per unit time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Variables\n",
    "Many continuous variables follow Gaussian distribution, thus deltas between samples of continuous variables are often modeled based on differences of Gaussian-distributed random variables. The most common statistical inference for this scenario is the good ole' [Student's t-test](https://en.wikipedia.org/wiki/Student%27s_t-test), referred to in ✨abracadabra✨ as `\"means_delta\"`, as it tests for differences in means of the underlying Gaussian distributions from each of treatments.\n",
    "\n",
    "Below we generate some Gaussian-distributed observations and show how ✨abracadabra✨can be used to run a t-test using the common `Experiment->HypothesisTest->HypothesisTestResults` workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some fake Gaussian-distributed trial data\n",
    "gaussian_data = generate_fake_observations(\n",
    "    distribution='gaussian',  # binary data\n",
    "    n_treatments=3,\n",
    "    n_attributes=4,\n",
    "    n_observations=1000\n",
    ")\n",
    "gaussian_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the `inference_method=\"means_delta\"` argument to run the t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the Experiment\n",
    "exper = Experiment(data=gaussian_data, name=\"Demo Experiment\")\n",
    "\n",
    "# Initialize the A/B test\n",
    "gaussian_ab_test = HypothesisTest(\n",
    "    metric=\"metric\",\n",
    "    treatment=\"treatment\",\n",
    "    control=\"A\", variation=\"B\",\n",
    "    hypothesis=\"unequal\",\n",
    "    inference_method=\"means_delta\"\n",
    ")\n",
    "\n",
    "# Run the test with an alpha of 0.5; get back a HypothesisTestResults object\n",
    "gaussian_ab_test_results = exper.run_test(gaussian_ab_test, alpha=.05)\n",
    "\n",
    "# Check the test results decision\n",
    "assert gaussian_ab_test_results.accept_hypothesis\n",
    "gaussian_ab_test_results.display()\n",
    "gaussian_ab_test_results.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian models for continuous variables\n",
    "The Bayesian analog to the t-test is called the \"Hierarchical Gaussian\" and involves modeling the observations as a generative process where each point is sampled from a Gaussian distribution with mean $\\mu$ and variance $\\sigma^2$. The model is \"hierarchical\" because it also assumes there is a distribution over both $\\mu$ and $\\sigma^2$ as well, namely $\\mu \\sim \\text{Normal}(\\bar{x}, \\text{std(x)})$ and $\\sigma \\sim \\text{Uniform}(0, \\sigma_{max})$, where $\\bar{x}$ and  $\\text{std(x)}$ are the empirical mean and standard deviation of the observations, and $\\sigma_{max}$ is a user-specified hyperparameter.\n",
    "\n",
    "\n",
    "That all sounds pretty complicated, right? Well, in ✨abracadabra✨ it's easy to run inference using this model. We simply update the `inference_method`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_gaussian_ab_test = ab_test.copy(inference_method='gaussian')\n",
    "\n",
    "# Run the test with an alpha of 0.5; get back a HypothesisTestResults object\n",
    "bayesian_gaussian_ab_test_results = exper.run_test(bayesian_gaussian_ab_test, alpha=.05)\n",
    "\n",
    "# Check the test results decision\n",
    "assert bayesian_gaussian_ab_test_results.accept_hypothesis\n",
    "bayesian_gaussian_ab_test_results.display()\n",
    "bayesian_gaussian_ab_test_results.visualize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts / Rates variables\n",
    "✨abracadabra✨ also supports analysis of counts variables such as clicks or page views per unit time. These discrete, countable variables often follow a Poisson distribution. Rather than modeling the _difference_ between the two treatments, we instead model whether the ratio of the two counts is statistically different than 1. The reasoning being that if the two treatments have the same number of counts per the same unit of time (and thus the same _rate_) then their ratio will be close to unity. Accordingly, in ✨abracadabra✨, this is called a `\"rates_ratio\"` inference method.\n",
    "\n",
    "Below we'll run an AB test on syntetic data drawn from a Poisson distribution, and test to see if the two distributions are statistically different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some fake Gaussian-distributed trial data\n",
    "counts_data = generate_fake_observations(\n",
    "    distribution='poisson',  # binary data\n",
    "    n_treatments=3,\n",
    "    n_observations=1000\n",
    ")\n",
    "counts_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the A/B test\n",
    "exper = Experiment(data=counts_data, name=\"Demo Experiment\")\n",
    "\n",
    "poisson_ab_test = HypothesisTest(\n",
    "    metric=\"metric\",\n",
    "    treatment=\"treatment\",\n",
    "    control=\"B\", variation=\"C\",\n",
    "    hypothesis=\"unequal\",\n",
    "    inference_method=\"rates_ratio\"\n",
    ")\n",
    "\n",
    "# Run the test with an alpha of 0.5; get back a HypothesisTestResults object\n",
    "poisson_ab_test_results = exper.run_test(poisson_ab_test, alpha=.05)\n",
    "\n",
    "# Check the test results decision\n",
    "poisson_ab_test_results.display()\n",
    "poisson_ab_test_results.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the ratio of the two rate parameters ranges between 1.38 and 1.68 (95% confidence), with no overlap with the value 1. This indicates that the variation `\"C\"`s location parameter is approximately 1.5x that of the control `\"B\"`, which makes sense, given the mean estimates for the two treatments are approximately 3 and 2, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian models for count variables\n",
    "The Bayesian analog to the rates ratio test is what's called the [Gamma-Poisson model](http://www.math.wm.edu/~leemis/chart/UDR/PDFs/Gammapoisson.pdf). In this model the observations are assumed to be generated from a Poisson distribution with location parameter $\\lambda$. Similarly to the \"Hierarchical Gaussian\" Bayesian, there is a prior distribution associated with $\\lambda$ (that's what makes it Bayesian!). Namely $\\lambda \\sim \\text{Gamma}(\\alpha, \\beta)$. Here the hyperparameters $\\alpha$ and $\\beta$ can be set by the experimenter to encode any intuitions or domain knowledge about the problem.\n",
    "\n",
    "Though this sounds complicated, implementing a hypothesis test using an inference method based off of the Gamma-Poisson model is not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bayesian_poisson_ab_test = poisson_ab_test.copy(inference_method='gamma_poisson')\n",
    "\n",
    "# Run the test with an alpha of 0.5; get back a HypothesisTestResults object\n",
    "bayesian_poisson_ab_test_results = exper.run_test(bayesian_poisson_ab_test)\n",
    "\n",
    "# Check the test results decision\n",
    "bayesian_poisson_ab_test_results.display()\n",
    "bayesian_poisson_ab_test_results.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that samples drawn from the Bayesian model provide similar central tendency interval estimates to those calculated by the analytical rates ratio model. However, unlike the rates ratio model which looks at the ratio of central tendencies, the Bayesian AB tests provides _deltas_ or differences amongst the rate parameter samples drawn from the model. Thus differences in $\\lambda$ samples that are far away from zero (in this case the diffence is--and should be--approximately equal to one) indicate significant difference between the treatments when interpreting the Bayesian counts AB test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
